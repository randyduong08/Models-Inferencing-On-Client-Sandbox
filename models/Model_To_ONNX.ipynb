{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"mount_file_id":"1t2q-loIWZQrFVIfg9xY0NXjRut2BVVPd","authorship_tag":"ABX9TyMxAT1LHrj2t496rwwcUHtH"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"id":"WNj19B1-r-k-","executionInfo":{"status":"ok","timestamp":1711399569586,"user_tz":240,"elapsed":23809,"user":{"displayName":"Randy Duong","userId":"01706691380119558100"}}},"outputs":[],"source":["import transformers\n","import transformers.convert_graph_to_onnx as onnx_convert\n","from pathlib import Path\n","from transformers import AutoTokenizer, AutoModelForSequenceClassification"]},{"cell_type":"code","source":["custom_model_path = \"/content/drive/MyDrive/Colab Notebooks/sentiment-ONNX/tuned_xtreme_model\"\n","\n","tokenizer = AutoTokenizer.from_pretrained(custom_model_path)\n","model = AutoModelForSequenceClassification.from_pretrained(custom_model_path)"],"metadata":{"id":"duMIZYRqsex7","executionInfo":{"status":"ok","timestamp":1711399577712,"user_tz":240,"elapsed":8128,"user":{"displayName":"Randy Duong","userId":"01706691380119558100"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["pipeline = transformers.pipeline(\"text-classification\", model=model, tokenizer=tokenizer)"],"metadata":{"id":"TaUSNUbas_0u","executionInfo":{"status":"ok","timestamp":1711399577712,"user_tz":240,"elapsed":13,"user":{"displayName":"Randy Duong","userId":"01706691380119558100"}}},"execution_count":3,"outputs":[]},{"cell_type":"code","source":["%pip install onnx onnxruntime"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"qr796s0iuk4M","executionInfo":{"status":"ok","timestamp":1711399592557,"user_tz":240,"elapsed":14857,"user":{"displayName":"Randy Duong","userId":"01706691380119558100"}},"outputId":"abe3430b-f697-4400-f519-5b453ff906db"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting onnx\n","  Downloading onnx-1.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (15.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m15.9/15.9 MB\u001b[0m \u001b[31m26.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting onnxruntime\n","  Downloading onnxruntime-1.17.1-cp310-cp310-manylinux_2_27_x86_64.manylinux_2_28_x86_64.whl (6.8 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.8/6.8 MB\u001b[0m \u001b[31m48.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy>=1.20 in /usr/local/lib/python3.10/dist-packages (from onnx) (1.25.2)\n","Requirement already satisfied: protobuf>=3.20.2 in /usr/local/lib/python3.10/dist-packages (from onnx) (3.20.3)\n","Collecting coloredlogs (from onnxruntime)\n","  Downloading coloredlogs-15.0.1-py2.py3-none-any.whl (46 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m46.0/46.0 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: flatbuffers in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.3.7)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (24.0)\n","Requirement already satisfied: sympy in /usr/local/lib/python3.10/dist-packages (from onnxruntime) (1.12)\n","Collecting humanfriendly>=9.1 (from coloredlogs->onnxruntime)\n","  Downloading humanfriendly-10.0-py2.py3-none-any.whl (86 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m86.8/86.8 kB\u001b[0m \u001b[31m11.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: mpmath>=0.19 in /usr/local/lib/python3.10/dist-packages (from sympy->onnxruntime) (1.3.0)\n","Installing collected packages: onnx, humanfriendly, coloredlogs, onnxruntime\n","Successfully installed coloredlogs-15.0.1 humanfriendly-10.0 onnx-1.16.0 onnxruntime-1.17.1\n"]}]},{"cell_type":"code","source":["ONNX_model_path = \"/content/drive/MyDrive/Colab Notebooks/sentiment-ONNX/ONNX_model/xtreme_distil_sentiment.onnx\"\n","onnx_convert.convert_pytorch(pipeline, opset=19, output=Path(ONNX_model_path), use_external_format=False)\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"HoGUu-4itK6V","executionInfo":{"status":"ok","timestamp":1711399595486,"user_tz":240,"elapsed":2932,"user":{"displayName":"Randy Duong","userId":"01706691380119558100"}},"outputId":"12c7099a-e5a8-42ba-edae-a1d72fe73288"},"execution_count":5,"outputs":[{"output_type":"stream","name":"stdout","text":["Using framework PyTorch: 2.2.1+cu121\n","Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n","Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n","Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n","Found output output_0 with shape: {0: 'batch'}\n","Ensuring inputs are in correct order\n","position_ids is not present in the generated input list.\n","Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.10/dist-packages/torch/onnx/utils.py:1548: OnnxExporterWarning: Exporting to ONNX opset version 19 is not supported. by 'torch.onnx.export()'. The highest opset version supported is 17. To use a newer opset version, consider 'torch.onnx.dynamo_export()'. Note that dynamo_export() is in preview. Please report errors with dynamo_export() as Github issues to https://github.com/pytorch/pytorch/issues.\n","  warnings.warn(\n"]}]}]}