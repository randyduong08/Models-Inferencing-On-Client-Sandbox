{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 7.407407407407407,
  "eval_steps": 500,
  "global_step": 600,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.62,
      "grad_norm": 42.59532165527344,
      "learning_rate": 9.419753086419753e-06,
      "loss": 2063.6431,
      "step": 50
    },
    {
      "epoch": 1.23,
      "grad_norm": 39.595062255859375,
      "learning_rate": 8.814814814814817e-06,
      "loss": 1899.5256,
      "step": 100
    },
    {
      "epoch": 1.85,
      "grad_norm": 35.58168029785156,
      "learning_rate": 8.197530864197532e-06,
      "loss": 1996.6937,
      "step": 150
    },
    {
      "epoch": 2.47,
      "grad_norm": 28.648643493652344,
      "learning_rate": 7.580246913580247e-06,
      "loss": 2055.2484,
      "step": 200
    },
    {
      "epoch": 3.09,
      "grad_norm": 18.545175552368164,
      "learning_rate": 6.962962962962964e-06,
      "loss": 1844.985,
      "step": 250
    },
    {
      "epoch": 3.7,
      "grad_norm": 8.46521282196045,
      "learning_rate": 6.345679012345679e-06,
      "loss": 1855.3216,
      "step": 300
    },
    {
      "epoch": 4.32,
      "grad_norm": 6.406212329864502,
      "learning_rate": 5.728395061728396e-06,
      "loss": 2023.9447,
      "step": 350
    },
    {
      "epoch": 4.94,
      "grad_norm": 6.289460182189941,
      "learning_rate": 5.1111111111111115e-06,
      "loss": 2005.1331,
      "step": 400
    },
    {
      "epoch": 5.56,
      "grad_norm": 8.88055419921875,
      "learning_rate": 4.493827160493827e-06,
      "loss": 2087.0244,
      "step": 450
    },
    {
      "epoch": 6.17,
      "grad_norm": 10.83547592163086,
      "learning_rate": 3.876543209876544e-06,
      "loss": 1858.4398,
      "step": 500
    },
    {
      "epoch": 6.79,
      "grad_norm": 9.50704288482666,
      "learning_rate": 3.25925925925926e-06,
      "loss": 1977.4927,
      "step": 550
    },
    {
      "epoch": 7.41,
      "grad_norm": 10.463424682617188,
      "learning_rate": 2.6419753086419752e-06,
      "loss": 1975.0391,
      "step": 600
    }
  ],
  "logging_steps": 50,
  "max_steps": 810,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 10,
  "save_steps": 200,
  "total_flos": 1.284149301018624e+17,
  "train_batch_size": 8,
  "trial_name": null,
  "trial_params": null
}
